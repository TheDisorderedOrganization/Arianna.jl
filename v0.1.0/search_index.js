var documenterSearchIndex = {"docs":
[{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"This is the documentation of the Arianna module's functions, types and structures.","category":"page"},{"location":"api/#API-Reference","page":"API","title":"API Reference","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"CurrentModule = Arianna","category":"page"},{"location":"api/#Index","page":"API","title":"Index","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"","category":"page"},{"location":"api/#Types-and-Functions","page":"API","title":"Types and Functions","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Modules = [Arianna]","category":"page"},{"location":"api/#Arianna.Arianna","page":"API","title":"Arianna.Arianna","text":"module Arianna\n\nArianna is a flexible and extensible framework for Monte Carlo simulations. Instead of acting as a black-box simulator, it   provides a modular structure where users define their own system and Monte Carlo \"moves\". \n\n\n\n\n\n","category":"module"},{"location":"api/#Arianna.Action","page":"API","title":"Arianna.Action","text":"abstract type Action\n\nAbstract type representing Monte Carlo actions/moves that can be performed on a system.\n\nConcrete subtypes must implement:\n\nsample_action!(action, policy, parameters, system, rng): Sample a new action from the policy\nperform_action!(system, action): Apply the action to modify the system state\ninvert_action!(action, system): Invert/reverse the action\nlog_proposal_density(action, policy, parameters, system): Log probability density of proposing this action\n\nOptional methods:\n\nperform_action_cached!(system, action): Optimized version of perform_action! that can reuse cached values\n\n\n\n\n\n","category":"type"},{"location":"api/#Arianna.AriannaAlgorithm","page":"API","title":"Arianna.AriannaAlgorithm","text":"abstract type AriannaAlgorithm\n\nAbstract type for Simulation algorithms.\n\n\n\n\n\n","category":"type"},{"location":"api/#Arianna.AriannaSystem","page":"API","title":"Arianna.AriannaSystem","text":"abstract type AriannaSystem\n\nAbstract type representing a system that can be simulated using methods defined in the Arianna module.\n\n\n\n\n\n","category":"type"},{"location":"api/#Arianna.DAT","page":"API","title":"Arianna.DAT","text":"DAT <: Format\n\nFormat type for data (.dat) file output.\n\n\n\n\n\n","category":"type"},{"location":"api/#Arianna.Format","page":"API","title":"Arianna.Format","text":"Format\n\nAbstract type for output file formats.\n\n\n\n\n\n","category":"type"},{"location":"api/#Arianna.Metropolis","page":"API","title":"Arianna.Metropolis","text":"Metropolis{P,R<:AbstractRNG,C<:Function} <: AriannaAlgorithm\n\nA struct representing a Metropolis Monte Carlo algorithm.\n\nFields\n\npools::Vector{P}: Vector of independent pools (one for each system)\nsweepstep::Int: Number of Monte Carlo steps per sweep\nseed::Int: Random number seed\nrngs::Vector{R}: Vector of random number generators\nparallel::Bool: Flag to parallelise over different threads\ncollecter::C: Transducer to collect results from parallelised loops\n\nType Parameters\n\nP: Type of the pool\nR: Type of the random number generator\nC: Type of the transducer\n\n\n\n\n\n","category":"type"},{"location":"api/#Arianna.Metropolis-Tuple{Any}","page":"API","title":"Arianna.Metropolis","text":"Metropolis(chains; pool=missing, sweepstep=1, seed=1, R=Xoshiro, parallel=false, extras...)\n\nCreate a new Metropolis instance.\n\nArguments\n\nchains: Vector of chains to run the algorithm on\npool: Pool of moves to perform sweeps over\nsweepstep: Number of Monte Carlo steps per sweep\nseed: Random number seed\nR: Type of the random number generator\nparallel: Flag to parallelise over different threads\nextras: Additional keyword arguments\n\nReturns\n\nalgorithm: Metropolis instance\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.Move","page":"API","title":"Arianna.Move","text":"Move{A<:Action,P<:Policy,V<:AbstractArray,T<:AbstractFloat}\n\nA struct representing a Monte Carlo move with an associated action, policy, and parameters.\n\nFields\n\naction::A: The action to be performed in the move\npolicy::P: The policy used to propose actions\nparameters::V: Parameters of the policy\nweight::T: Weight/probability of selecting this move in a sweep\ntotal_calls::Int: Total number of times this move has been attempted\naccepted_calls::Int: Number of times this move has been accepted\n\nType Parameters\n\nA: Type of the action\nP: Type of the policy\nV: Type of the parameter array\nT: Type of the weight (floating point)\n\n\n\n\n\n","category":"type"},{"location":"api/#Arianna.Move-NTuple{4, Any}","page":"API","title":"Arianna.Move","text":"Move(action, policy, parameters, weight)\n\nCreate a new Move instance.\n\nArguments\n\naction: The action to be performed in the move\npolicy: The policy used to propose actions\nparameters: Parameters of the policy\nweight: Weight/probability of selecting this move in a sweep\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.Policy","page":"API","title":"Arianna.Policy","text":"abstract type Policy\n\nAbstract type representing proposal policies for Monte Carlo actions.\n\nA Policy defines how actions are sampled and their proposal probabilities are calculated. Concrete subtypes work together with specific Action types to implement the proposal mechanism.\n\n\n\n\n\n","category":"type"},{"location":"api/#Arianna.PrintTimeSteps","page":"API","title":"Arianna.PrintTimeSteps","text":"PrintTimeSteps <: AriannaAlgorithm\n\nAlgorithm to display a progress bar and current timestep during simulation.\n\n\n\n\n\n","category":"type"},{"location":"api/#Arianna.Simulation","page":"API","title":"Arianna.Simulation","text":"mutable struct Simulation{S, A, VS}\n\nA structure representing a Monte Carlo simulation.\n\nFields\n\nchains::Vector{S}: Vector of independent Arianna systems.\nalgorithms::A: List of algorithms.\nsteps::Int: Number of MC sweeps.\nt::Int: Current time step.\nschedulers::VS: List of schedulers (one for each algorithm).\ncounters::Vector{Int}: Counters for the schedulers (one for each algorithm).\npath::String: Simulation path.\nverbose::Bool: Flag for verbose output.\n\n\n\n\n\n","category":"type"},{"location":"api/#Arianna.Simulation-Tuple{Any, Any, Any}","page":"API","title":"Arianna.Simulation","text":"Simulation(chains, algorithm_list, steps; path=\"data\", verbose=false)\n\nCreate a new Simulation instance from a list of algorithm constructors.\n\nArguments\n\nchains: Vector of independent Arianna systems.\nalgorithm_list: List of algorithm constructors.\nsteps: Number of MC sweeps.\npath=\"data\": Simulation path.\nverbose=false: Flag for verbose output.\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.StoreBackups","page":"API","title":"Arianna.StoreBackups","text":"StoreBackups <: AriannaAlgorithm\n\nAlgorithm to create backup files of system states during simulation.\n\nFields\n\ndirs::Vector{String}: Directories for storing backup files\nfmt::Format: Format type for output files\nstore_first::Bool: Whether to store backups at initialization\nstore_last::Bool: Whether to store backups at finalization\n\n\n\n\n\n","category":"type"},{"location":"api/#Arianna.StoreCallbacks","page":"API","title":"Arianna.StoreCallbacks","text":"StoreCallbacks{V} <: AriannaAlgorithm\n\nAlgorithm to store callback values during simulation.\n\nFields\n\ncallbacks::V: Vector of callback functions to evaluate\npaths::Vector{String}: Paths to output files for each callback\nfiles::Vector{IOStream}: File handles for writing callback values\nstore_first::Bool: Whether to store callback values at initialization\nstore_last::Bool: Whether to store callback values at finalization\n\nConstructor\n\nStoreCallbacks(callbacks::V, path; store_first::Bool=true, store_last::Bool=false)\n\nCreate a new StoreCallbacks instance.\n\nArguments\n\ncallbacks::V: Vector of callback functions\npath: Base path for output files\nstore_first=true: Store values at initialization\nstore_last=false: Store values at finalization\n\n\n\n\n\n","category":"type"},{"location":"api/#Arianna.StoreLastFrames","page":"API","title":"Arianna.StoreLastFrames","text":"StoreLastFrames <: AriannaAlgorithm\n\nAlgorithm to store the final state of each system at the end of simulation.\n\nFields\n\npaths::Vector{String}: Paths to output files\nfmt::Format: Format type for output files\n\n\n\n\n\n","category":"type"},{"location":"api/#Arianna.StoreParameters","page":"API","title":"Arianna.StoreParameters","text":"StoreParameters{V<:AbstractArray} <: AriannaAlgorithm\n\nA struct representing a parameter store.\n\nFields\n\npaths::Vector{String}: Vector of paths to the parameter files\nfiles::Vector{IOStream}: Vector of open file streams to the parameter files\nparameters_list::V: List of parameters to store\nstore_first::Bool: Flag to store the parameters at the first step\nstore_last::Bool: Flag to store the parameters at the last step\n\nType Parameters\n\nV: Type of the parameter array\n\n\n\n\n\n","category":"type"},{"location":"api/#Arianna.StoreParameters-Tuple{Any}","page":"API","title":"Arianna.StoreParameters","text":"StoreParameters(chains; dependencies=missing, path=missing, ids=missing, store_first=true, store_last=false, extras...)\n\nCreate a new StoreParameters instance.\n\nArguments\n\nchains: Vector of chains to store the parameters of\ndependencies: Dependencies of the parameter store\npath: Path to the parameter files\nids: IDs of the parameters to store\nstore_first: Flag to store the parameters at the first step\nstore_last: Flag to store the parameters at the last step\nextras: Additional keyword arguments\n\nReturns\n\nalgorithm: StoreParameters instance\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.StoreTrajectories","page":"API","title":"Arianna.StoreTrajectories","text":"StoreTrajectories{F<:Format} <: AriannaAlgorithm\n\nAlgorithm to store system trajectories during simulation.\n\nFields\n\npaths::Vector{String}: Paths to output files\nfiles::Vector{IOStream}: File handles for writing trajectories\nfmt::F: Format type for output files\nstore_first::Bool: Whether to store trajectories at initialization\nstore_last::Bool: Whether to store trajectories at finalization\n\n\n\n\n\n","category":"type"},{"location":"api/#Arianna.TXT","page":"API","title":"Arianna.TXT","text":"TXT <: Format\n\nFormat type for text (.txt) file output.\n\n\n\n\n\n","category":"type"},{"location":"api/#Arianna.build_schedule-Tuple{Int64, Int64, AbstractFloat}","page":"API","title":"Arianna.build_schedule","text":"build_schedule(steps::Int, burn::Int, base::AbstractFloat)\n\nCreate a vector of timestep from burn to steps log-spaced with base base.\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.build_schedule-Tuple{Int64, Int64, Int64}","page":"API","title":"Arianna.build_schedule","text":"build_schedule(steps::Int, burn::Int, Δt::Int)\n\nCreate a vector of timestep from burn to steps at intervals Δt.\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.build_schedule-Tuple{Int64, Int64, Vector{Int64}}","page":"API","title":"Arianna.build_schedule","text":"build_schedule(steps::Int, burn::Int, block::Vector{Int})\n\nCreate a vector of timestep from burn to steps with repeated blocks specified by block.\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.callback_acceptance-Tuple{Any}","page":"API","title":"Arianna.callback_acceptance","text":"callback_acceptance(simulation)\n\nCalculate the mean acceptance rate of the Metropolis algorithm.\n\nArguments\n\nsimulation: Simulation to calculate the acceptance rate of\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.delta_log_target_density-Tuple{Any, Any, AriannaSystem}","page":"API","title":"Arianna.delta_log_target_density","text":"delta_log_target_density(x₁, x₂, system::AriannaSystem)\n\nCalculate the change in log target density between two states.\n\nArguments\n\nx₁: Initial state\nx₂: Final state\nsystem: System object\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.finalise-Tuple{AriannaAlgorithm, Simulation}","page":"API","title":"Arianna.finalise","text":"finalise(::AriannaAlgorithm, ::Simulation)\n\nFinalise the algorithm for the given simulation.\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.finalise-Tuple{StoreLastFrames, Simulation}","page":"API","title":"Arianna.finalise","text":"store_lastframe(io, system, t, fmt::Format)\n\nStore the final state of the system at time t to the given IO stream in the specified format.\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.initialise-Tuple{AriannaAlgorithm, Simulation}","page":"API","title":"Arianna.initialise","text":"initialise(::AriannaAlgorithm, ::Simulation)\n\nInitialise the algorithm for the given simulation.\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.initialise-Tuple{StoreBackups, Simulation}","page":"API","title":"Arianna.initialise","text":"store_backup(io, system, t, fmt::Format)\n\nStore a backup of the system state at time t to the given IO stream in the specified format.\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.invert_action!-Tuple{Action, AriannaSystem}","page":"API","title":"Arianna.invert_action!","text":"invert_action!(action::Action, system::AriannaSystem)\n\nInvert/reverse an action.\n\nArguments\n\naction: Action to invert\nsystem: System the action was applied to\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.log_proposal_density-Tuple{Any, Any, Any, AriannaSystem}","page":"API","title":"Arianna.log_proposal_density","text":"log_proposal_density(action, policy, parameters, system::AriannaSystem)\n\nCalculate the log probability density of proposing the given action.\n\nArguments\n\naction: Proposed action\npolicy: Policy used for proposal\nparameters: Parameters of the policy\nsystem: System the action is applied to\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.make_step!-Tuple{Simulation, AriannaAlgorithm}","page":"API","title":"Arianna.make_step!","text":"make_step!(::Simulation, ::AriannaAlgorithm)\n\nPerform a single step of the algorithm in the simulation.\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.make_step!-Tuple{Simulation, Metropolis}","page":"API","title":"Arianna.make_step!","text":"make_step!(simulation::Simulation, algorithm::Metropolis)\n\nPerform a single step of the Metropolis algorithm.\n\nArguments\n\nsimulation: Simulation to perform the step on\nalgorithm: Metropolis instance\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.mc_step!-Union{Tuple{T}, Tuple{AriannaSystem, Action, Policy, AbstractArray{T}, Any}} where T<:AbstractFloat","page":"API","title":"Arianna.mc_step!","text":"mc_step!(system::AriannaSystem, action::Action, policy::Policy, parameters::AbstractArray{T}, rng) where {T<:AbstractFloat}\n\nPerform a single Monte Carlo step.\n\nArguments\n\nsystem: System to modify\naction: Action to perform\npolicy: Policy used for proposal\nparameters: Parameters of the policy\nrng: Random number generator\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.mc_sweep!-Tuple{AriannaSystem, Any, Any}","page":"API","title":"Arianna.mc_sweep!","text":"mc_sweep!(system::AriannaSystem, pool, rng; mc_steps=1)\n\nPerform a Monte Carlo sweep over a pool of moves.\n\nArguments\n\nsystem: System to modify\npool: Pool of moves to perform sweeps over\nrng: Random number generator\nmc_steps: Number of Monte Carlo steps per sweep\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.perform_action!-Tuple{AriannaSystem, Action}","page":"API","title":"Arianna.perform_action!","text":"perform_action!(system::AriannaSystem, action::Action)\n\nApply the action to modify the system state.\n\nArguments\n\nsystem: System to modify\naction: Action to perform\n\nReturns\n\nA tuple of (x₁, x₂) containing the old and new states\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.perform_action_cached!-Tuple{AriannaSystem, Action}","page":"API","title":"Arianna.perform_action_cached!","text":"perform_action_cached!(system, action::Action)\n\nOptimized version of perform_action! that can reuse cached values.\n\nArguments\n\nsystem: System to modify\naction: Action to perform\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.raise_error-Tuple{Any}","page":"API","title":"Arianna.raise_error","text":"raise_error(s)\n\nHelper function to raise errors for unimplemented required methods.\n\nArguments\n\ns: String describing the missing method implementation\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.run!-Tuple{Simulation}","page":"API","title":"Arianna.run!","text":"run!(simulation::Simulation)\n\nRun the Monte Carlo simulation.\n\nArguments\n\nsimulation::Simulation: The simulation instance to run.\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.sample_action!-Tuple{Action, Policy, Any, AriannaSystem, Any}","page":"API","title":"Arianna.sample_action!","text":"sample_action!(action::Action, policy::Policy, parameters, system::AriannaSystem, rng)\n\nSample a new action from the policy.\n\nArguments\n\naction: Action to be sampled\npolicy: Policy to sample from\nparameters: Parameters of the policy\nsystem: System the action will be applied to\nrng: Random number generator\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.store_trajectory-Tuple{Any, AriannaSystem, Any, Arianna.Format}","page":"API","title":"Arianna.store_trajectory","text":"store_trajectory(io, system::AriannaSystem, t, fmt::Format)\n\nStore the system trajectory at time t to the given IO stream in the specified format.\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.unnormalised_log_target_density-Tuple{Any, AriannaSystem}","page":"API","title":"Arianna.unnormalised_log_target_density","text":"unnormalised_log_target_density(x, system)\n\nCalculate the unnormalized log probability density of a system state.\n\nArguments\n\nx: System state\nsystem: System object\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.write_algorithm-Tuple{Any, AriannaAlgorithm, Any}","page":"API","title":"Arianna.write_algorithm","text":"write_algorithm(io, algorithm::AriannaAlgorithm, scheduler)\n\nWrite a summary of the algorithm on the given IO stream.\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.write_algorithm-Tuple{Any, Metropolis, Any}","page":"API","title":"Arianna.write_algorithm","text":"write_algorithm(io, algorithm::Metropolis, scheduler)\n\nWrite the algorithm to a string.\n\nArguments\n\nio: IO stream to write to\nalgorithm: Algorithm to write\nscheduler: Scheduler to write\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.write_parameters-Tuple{Policy, Any}","page":"API","title":"Arianna.write_parameters","text":"write_parameters(::Policy, parameters)\n\nWrite the parameters of a policy to a string.\n\nArguments\n\npolicy: Policy to write the parameters of\nparameters: Parameters of the policy\n\n\n\n\n\n","category":"method"},{"location":"api/#Arianna.jl","page":"API","title":"Arianna.jl","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"```@autodocs","category":"page"},{"location":"man/system/#Adding-Your-Own-System","page":"Adding Your Own System","title":"Adding Your Own System","text":"","category":"section"},{"location":"man/system/","page":"Adding Your Own System","title":"Adding Your Own System","text":"Now that you understand how to run a Monte Carlo (MC) simulation, you may want to extend the framework by defining your own system. The particle_1d.jl  file provides a minimal example of a system, which you can use as a reference when creating a new one.","category":"page"},{"location":"man/system/","page":"Adding Your Own System","title":"Adding Your Own System","text":"To define a new system, you need to specify its state variables, Monte Carlo moves and how to perform them. These components determine how the system evolves during the simulation. A system consists of:","category":"page"},{"location":"man/system/#System","page":"Adding Your Own System","title":"System","text":"","category":"section"},{"location":"man/system/","page":"Adding Your Own System","title":"Adding Your Own System","text":"Specify the state representation and the target probability density.","category":"page"},{"location":"man/system/","page":"Adding Your Own System","title":"Adding Your Own System","text":"State representation: Defines the key quantities describing the system (e.g., position, energy, temperature). Your system has to be a struct where each element is a state variable. Example:","category":"page"},{"location":"man/system/","page":"Adding Your Own System","title":"Adding Your Own System","text":"mutable struct Particle{T<:AbstractFloat}\n    x::T\n    β::T\n    e::T\nend","category":"page"},{"location":"man/system/","page":"Adding Your Own System","title":"Adding Your Own System","text":"Target density: This is the (unnormalised) log-density of the system. In this case it's simply the Boltzmann distribution at inverse temperature beta. Note that it takes a generic state as input instead of the whole system object. This is better for performance, as generally the density only depends on a few properties of the system. In this case state is a tuple defined as (e, β).","category":"page"},{"location":"man/system/","page":"Adding Your Own System","title":"Adding Your Own System","text":"function Arianna.unnormalised_log_target_density(state, ::Particle)\n    return -state[1] * state[2]\nend","category":"page"},{"location":"man/system/#Monte-Carlo-move","page":"Adding Your Own System","title":"Monte Carlo move","text":"","category":"section"},{"location":"man/system/","page":"Adding Your Own System","title":"Adding Your Own System","text":"Specify how the system state changes during the simulation","category":"page"},{"location":"man/system/","page":"Adding Your Own System","title":"Adding Your Own System","text":"Define an action. In the example, the action is a displacement.","category":"page"},{"location":"man/system/","page":"Adding Your Own System","title":"Adding Your Own System","text":"mutable struct Displacement{T<:AbstractFloat} <: Action\n    δ::T\nend","category":"page"},{"location":"man/system/","page":"Adding Your Own System","title":"Adding Your Own System","text":"Define how this action is sampled in the sample_action! function. In the example, the displacement length is sampled from a normal distribution.","category":"page"},{"location":"man/system/","page":"Adding Your Own System","title":"Adding Your Own System","text":"function Arianna.sample_action!(action::Displacement,::StandardGaussian, parameters, system::Particle, rng)\n    action.δ = rand(rng, Normal(zero(action.δ), parameters.σ))\n    return nothing\nend","category":"page"},{"location":"man/system/","page":"Adding Your Own System","title":"Adding Your Own System","text":"Specify the probablity of proposing the action in log_proposal_density. Note that this function must give the exact probability of sampling the action with sample_action!. In this case, we just need the density of the normal distribution.","category":"page"},{"location":"man/system/","page":"Adding Your Own System","title":"Adding Your Own System","text":"function Arianna.log_proposal_density(action::Displacement, ::StandardGaussian, parameters, system::Particle)\n    return -(action.δ)^2 / (2parameters.σ^2) - log(2π * parameters.σ^2) / 2\nend","category":"page"},{"location":"man/system/","page":"Adding Your Own System","title":"Adding Your Own System","text":"Finally, provide how this action changes the state of the system in the perform_action! function. In the example, performing the displacement updates the position and the energy of the particle. Note that perform_action! returns information on the state of the system before and after the action. This doesn't have to be the whole system, but just the part relevant for evaluating the density ratio in delta_log_target_density.","category":"page"},{"location":"man/system/","page":"Adding Your Own System","title":"Adding Your Own System","text":"function Arianna.perform_action!(system::Particle, action::Displacement)\n    e₁ = system.e\n    system.x += action.δ\n    system.e = potential(system.x)\n    return (e₁, system.β), (system.e, system.β)\nend","category":"page"},{"location":"man/system/","page":"Adding Your Own System","title":"Adding Your Own System","text":"By modifying and extending the existing particle_1D.jl example, you can create a variety of physical and mathematical models suitable for MC simulations.","category":"page"},{"location":"related/#Related-packages","page":"Related packages","title":"Related packages","text":"","category":"section"},{"location":"related/","page":"Related packages","title":"Related packages","text":"There are many established Monte Carlo frameworks, each with different focuses. Arianna is designed to offer full flexibility in defining Monte Carlo moves and system-specific updates. Unlike black-box MCMC samplers, it allows users to implement custom moves (think of cluster updates in spin models) or domain-specific sampling strategies. Additionally, Arianna includes an adaptive Monte Carlo framework (via the PolicyGuided module) that dynamically adapt Monte Carlo moves to maximise sampling efficiency.","category":"page"},{"location":"related/","page":"Related packages","title":"Related packages","text":"For MCMC sampling, some related packages include:","category":"page"},{"location":"related/","page":"Related packages","title":"Related packages","text":"Turing.jl – A probabilistic programming library for Bayesian inference, built on MCMC methods like Metropolis-Hastings and Hamiltonian Monte Carlo.\nAdvancedMH.jl – A package that provides enhanced Metropolis-Hastings algorithms with flexible proposal distributions.","category":"page"},{"location":"related/","page":"Related packages","title":"Related packages","text":"For more general Monte Carlo and physics-based simulations:","category":"page"},{"location":"related/","page":"Related packages","title":"Related packages","text":"MonteCarloX.jl – A Monte Carlo package package similar in spirit to Arianna that separates the algorithmic part from the system.\nMolly.jl – A molecular dynamics package exposing internals for customization that can also perform basic Monte Carlo simulations.\nMonteCarlo.jl – A framework for Monte Carlo simulations with support for various sampling techniques, mostly oriented to spin systems and Quantum Monte Carlo.","category":"page"},{"location":"related/","page":"Related packages","title":"Related packages","text":"Arianna differentiates itself by prioritising flexibility in move design and adaptive sampling, making it particularly useful for physics-inspired Monte Carlo methods beyond standard statistical MCMC applications.","category":"page"},{"location":"man/montecarlo/#Markov-Chain-Monte-Carlo","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"","category":"section"},{"location":"man/montecarlo/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Markov Chain Monte Carlo (MCMC) methods are a class of algorithms designed for exact sampling from a target probability distribution P defined on a measurable space (mathcal X Sigma). They achieve this by constructing a Markov chain leftX_muright_mu=1^M that has P as its equilibrium distribution. These methods are particularly useful when direct sampling is difficult. Once the chain has been constructed, the expected value of any quantity mathcal A can be estimated as the empirical average","category":"page"},{"location":"man/montecarlo/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"mathbb E_Pleftmathcal Aleft(xright)right=lim_Mto+inftysum_mu=1^Mmathcal Aleft(X_muright)","category":"page"},{"location":"man/montecarlo/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Building such a chain requires specifying a transition kernel Kleft(xXright), which quantifies the conditional probability for transitioning from state xinmathcal X to any state xin XsubseteqSigma. A sufficient condition for sampling the correct target distribution is that K satisfies the detailed balance relation","category":"page"},{"location":"man/montecarlo/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Pleft(mathrm dxright)Kleft(xmathrm dxright)=Pleft(mathrm dxright)Kleft(xmathrm dxright)","category":"page"},{"location":"man/montecarlo/#The-Metropolis-Hastings-Algorithm","page":"Markov Chain Monte Carlo","title":"The Metropolis-Hastings Algorithm","text":"","category":"section"},{"location":"man/montecarlo/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"The Metropolis-Hastings (MH) algorithm is one of the most widely used MCMC methods. It works by separating the transition kernel K into a proposal and acceptance step:","category":"page"},{"location":"man/montecarlo/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Starting from the current state x, a new state x is drawn from the proposal distribution Qleft(xXright).\nThe transition is accepted with probability","category":"page"},{"location":"man/montecarlo/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"alphaleft(xxright)=minleft1fracPleft(mathrm dxright)Qleft(xmathrmdxright)Pleft(mathrm dxright)Qleft(xmathrmdxright)right","category":"page"},{"location":"man/montecarlo/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"and rejected with probability 1-alphaleft(xxright). Provided that the proposal distribution Q guarantees ergodicity, the condition of detailed balance ensures that the MH algorithm eventually samples the desired distribution P.","category":"page"},{"location":"man/montecarlo/#Implementation-in-Arianna","page":"Markov Chain Monte Carlo","title":"Implementation in Arianna","text":"","category":"section"},{"location":"man/montecarlo/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"In Arianna, the Metropolis-Hastings algorithm is implemented through the Metropolis struct, which requires:","category":"page"},{"location":"man/montecarlo/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"A system state representation\nA pool of Monte Carlo moves (actions)\nProposal distributions (policies) for generating new states\nFunctions to calculate:\nThe log target density (unnormalised_log_target_density)\nThe log proposal density (log_proposal_density)\nHow to sample an action (sample_action!)\nHow to perform actions (perform_action!)","category":"page"},{"location":"man/montecarlo/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"See the Adding Your Own System section for details on implementing these components for your specific problem.","category":"page"},{"location":"man/policyguided/#Policy-guided-Monte-Carlo","page":"Policy-guided Monte Carlo","title":"Policy-guided Monte Carlo","text":"","category":"section"},{"location":"man/policyguided/","page":"Policy-guided Monte Carlo","title":"Policy-guided Monte Carlo","text":"Policy-guided Monte Carlo (PGMC) is an adaptive Monte Carlo method that dynamically adjusts the proposal distribution in the Metropolis-Hastings (MH) kernel to maximise sampling efficiency, using a formalism inspired by reinforcement learning.","category":"page"},{"location":"man/policyguided/","page":"Policy-guided Monte Carlo","title":"Policy-guided Monte Carlo","text":"As long as the proposal distribution Q guarantees ergodicity, here is significant flexibility in the choice of its specific form. PGMC aims at finding an optimal proposal distribution that maximises some measure of  efficiency of the Markov chain. To do this, it needs a reward function rleft(xxright) that quantifies the performance of a single transition xto x. The reward function must satisfy the constraint rleft(xxright)=0. This can be used to define the objective function","category":"page"},{"location":"man/policyguided/","page":"Policy-guided Monte Carlo","title":"Policy-guided Monte Carlo","text":"Jleft(Qright)=mathbb E_substackxsim P  xsim Kleftrleft(xxright)right","category":"page"},{"location":"man/policyguided/","page":"Policy-guided Monte Carlo","title":"Policy-guided Monte Carlo","text":"that is nothing but the average reward over the Markov chain.","category":"page"},{"location":"man/policyguided/","page":"Policy-guided Monte Carlo","title":"Policy-guided Monte Carlo","text":"The goal is to find a proposal distribution Q^star that maximises the objective function J. To practically tackle the problem, we restrict the search to a family of distributions Q_theta​ parameterised by a real vector theta. Starting from an initial guess, we then update theta iteratively according to the stochastic gradient ascent procedure","category":"page"},{"location":"man/policyguided/","page":"Policy-guided Monte Carlo","title":"Policy-guided Monte Carlo","text":"thetaleftarrowtheta +etawidehatnabla_theta J","category":"page"},{"location":"man/policyguided/","page":"Policy-guided Monte Carlo","title":"Policy-guided Monte Carlo","text":"where eta is the learning rate and widehatnabla_theta J is a stochastic estimate of the actual gradient of J with respect to theta.","category":"page"},{"location":"man/policyguided/#Implementation-in-Arianna","page":"Policy-guided Monte Carlo","title":"Implementation in Arianna","text":"","category":"section"},{"location":"man/policyguided/","page":"Policy-guided Monte Carlo","title":"Policy-guided Monte Carlo","text":"Arianna implements PGMC through two core algorithms found in the submodule PolicyGuided:","category":"page"},{"location":"man/policyguided/","page":"Policy-guided Monte Carlo","title":"Policy-guided Monte Carlo","text":"PolicyGradientEstimator computes widehatnabla_theta J for each move in the pool by drawing multiple samples from P and Q.\nPolicyGradientUpdate applies the estimated gradient to update the move parameters. The PolicyGuided module provides several advanced optimisers, including natural gradients methods.","category":"page"},{"location":"man/policyguided/#Running-a-PGMC-simulation","page":"Policy-guided Monte Carlo","title":"Running a PGMC simulation","text":"","category":"section"},{"location":"man/policyguided/","page":"Policy-guided Monte Carlo","title":"Policy-guided Monte Carlo","text":"To make your Monte Carlo simulation adaptive, simply add the two algorithms from PolicyGuided to the simulation. The following Julia script demonstrates this in the particle_1D.jl example","category":"page"},{"location":"man/policyguided/","page":"Policy-guided Monte Carlo","title":"Policy-guided Monte Carlo","text":"include(\"example/particle_1D/particle_1d.jl\")\n\nx₀ = 0.0\nβ = 2.0\nM = 10\nchains = [System(x₀, β) for _ in 1:M]\npool = (Move(Displacement(0.0), StandardGaussian(), ComponentArray(σ=0.1), 1.0),)\nseed = 42\noptimisers = (VPG(0.001),)\nsteps = 10^5\nburn = 1000\nsampletimes = build_schedule(steps, burn, 10)\npath = \"data/PGMC/particle_1d/Harmonic/beta$β/M$M/seed$seed\"\nalgorithm_list = (\n    (algorithm=Metropolis, pool=pool, seed=seed, parallel=false),\n    (algorithm=PolicyGradientEstimator, dependencies=(Metropolis,), optimisers=optimisers, parallel=false),\n    (algorithm=PolicyGradientUpdate, dependencies=(PolicyGradientEstimator,), scheduler=build_schedule(steps, burn, 2)),\n    (algorithm=StoreCallbacks, callbacks=(callback_energy, callback_acceptance), scheduler=sampletimes),\n    (algorithm=StoreTrajectories, scheduler=sampletimes),\n    (algorithm=StoreParameters, dependencies=(Metropolis,), scheduler=sampletimes),\n    (algorithm=PrintTimeSteps, scheduler=build_schedule(steps, burn, steps ÷ 10)),\n)\nsimulation = Simulation(chains, algorithm_list, steps; path=path, verbose=true)\nrun!(simulation)","category":"page"},{"location":"man/policyguided/","page":"Policy-guided Monte Carlo","title":"Policy-guided Monte Carlo","text":"In this example, PGMC optimises the standard deviation σ of the Gaussian-distributed displacements using the VPG optimiser with a learing rate of 0.001. Note that PolicyGradientUpdate is called every two calls of PolicyGradientEstimator to accumulate more samples for gradient estimation before each update.","category":"page"},{"location":"#Arianna","page":"Home","title":"Arianna","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"A system-agnostic approach to Monte Carlo simulationsArianna is a flexible and extensible framework for Monte Carlo simulations. Instead of acting as a black-box simulator, it provides a modular structure where users define their own system and Monte Carlo \"moves\". The package includes some simple predefined systems for example purposes, and more complex systems are defined in other repos like ParticlesMC.","category":"page"},{"location":"#Features","page":"Home","title":"Features","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"General-Purpose Monte Carlo Engine: A lightweight framework that provides the core algorithms for Monte Carlo sampling, allowing users to define their own systems, moves, and proposal distributions.\nExtensible Algorithms: Built-in support for Metropolis-Hastings with the flexibility to implement advanced techniques like event-chain Monte Carlo.\nPolicy-Guided Monte Carlo: Integrates adaptive sampling using policy gradient methods to optimise move parameters dynamically.\nPredefined Systems: Includes simple examples to help users get started quickly, with additional system implementations available through companion repositories like ParticlesMC.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To install the Arianna module, you can clone the repository and use the Julia package manager to add the module path to your environment.","category":"page"},{"location":"","page":"Home","title":"Home","text":"git clone https://github.com/TheDisorderedOrganization/Arianna.jl.git\ncd Arianna\njulia -e 'using Pkg; Pkg.activate(\".\"); Pkg.instantiate()'","category":"page"},{"location":"#Usage","page":"Home","title":"Usage","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Arianna is designed to work with user-defined systems rather than providing predefined ones. However, to help users get started, we provide example cases such as particle_1D.jl in the example folder. Once you have defined your system and the associated moves, Arianna allows you to run Monte Carlo simulations and store relevant data. The following Julia script illustrates how to set up and execute a general simulation in the particle_1D.jl example.","category":"page"},{"location":"","page":"Home","title":"Home","text":"include(\"example/particle_1D/particle_1d.jl\")\n\nx₀ = 0.0\nβ = 2.0\nM = 10\nchains = [System(x₀, β) for _ in 1:M]\npool = (Move(Displacement(0.0), StandardGaussian(), ComponentArray(σ=0.1), 1.0),)\nsteps = 10^5\nburn = 1000\nsampletimes = build_schedule(steps, burn, 10)\npath = \"data/MC/particle_1d/Harmonic/beta$β/M$M/seed$seed\"\n\nalgorithm_list = (\n    (algorithm=Metropolis, pool=pool, seed=seed, parallel=false),\n    (algorithm=StoreCallbacks, callbacks=(callback_energy, callback_acceptance), scheduler=sampletimes),\n    (algorithm=StoreTrajectories, scheduler=sampletimes),\n) \n\nsimulation = Simulation(chains, algorithm_list, steps; path=path, verbose=true)\nrun!(simulation)","category":"page"},{"location":"","page":"Home","title":"Home","text":"This implementation employs the Metropolis algorithm for Monte Carlo sampling of multiple independent chains, using Gaussian-distributed displacements as proposed moves. The simulation records energy and acceptance statistics while storing particle trajectories for analysis. The resulting data is saved in the specified output directory for further evaluation.","category":"page"},{"location":"#Contributing","page":"Home","title":"Contributing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"We welcome contributions from the community. If you have a new system or feature to add, please fork the repository, make your changes, and submit a pull request.","category":"page"},{"location":"#Citing","page":"Home","title":"Citing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you use Arianna in your research, please cite it! You can find the citation information in the CITATION file or directly through GitHub’s \"Cite this repository\" button.","category":"page"},{"location":"#License","page":"Home","title":"License","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This project is licensed under the GNU General Public License v3.0.  License. See the LICENSE file for details.","category":"page"},{"location":"#Contact","page":"Home","title":"Contact","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"For any questions or issues, please open an issue on the GitHub repository or contact the maintainers.","category":"page"}]
}
